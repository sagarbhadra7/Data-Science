{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "My_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFIMgd5gwr+KjFEwsivxdp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagarbhadra7/Python-Programs/blob/master/My_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlIwL6xxCnro",
        "colab_type": "text"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxneTyvS2U_B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import maths\n",
        "import missingno as mi # for missing data presentation\n",
        "import pandas.util.testing as tm\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOszxdrqCtm9",
        "colab_type": "text"
      },
      "source": [
        "## Data loading and spliting in target and features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOVjXHmH--Ri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data reading using pandas\n",
        "path=\"\"\n",
        "df=pd.read_csv(path)\n",
        "X=df.drop([''],axis=1)\n",
        "y=df[''].copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVJZ3BsYCzUo",
        "colab_type": "text"
      },
      "source": [
        "## To check the first 5 rows of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hkXo1CvAivz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNMLuFu9C3HW",
        "colab_type": "text"
      },
      "source": [
        "## to describe data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR2dUxAFAkHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h6y3HuEC7hh",
        "colab_type": "text"
      },
      "source": [
        "## Information regardin the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM-QCOMpAr3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-W20cGgC_IO",
        "colab_type": "text"
      },
      "source": [
        "## TO check the null values in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4c-DQV1AdFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to check the null values in dataset\n",
        "X.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tcte1FU7DE1u",
        "colab_type": "text"
      },
      "source": [
        "## To check the duplicates rows in data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg2PFQH0DD6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Rows containing duplicate data\n",
        "duplicate_rows_df = X[X.duplicated()]\n",
        "print(\"number of duplicate rows: \", duplicate_rows_df.shape)\n",
        "\n",
        "print(“number of duplicate rows: “, duplicate_rows_df.shape)\n",
        "\n",
        "# Dropping the duplicates \n",
        "X = X.drop_duplicates()\n",
        "X.head(5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4KdTXBODdA1",
        "colab_type": "text"
      },
      "source": [
        "## To seprate categorical and Numerical features from data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MawqtnoE_Oyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To seprate categorical and numerical features\n",
        "# Seperate continuous variables and categorical variables\n",
        "#dataframe_con = dataframe.select_dtypes(include=np.number)\n",
        "#dataframe_cat = dataframe.select_dtypes(exclude=np.number)\n",
        "numerics = ['int16','int32','int64','float16','float32','float64']\n",
        "numerical_vars = list(X.select_dtypes(include=numerics).columns)\n",
        "df_numeric=X.loc[:,numerical_vars]\n",
        "\n",
        "# to generate categorical value\n",
        "df_category=X.drop(numerical_vars,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBm3RTH_Dtd8",
        "colab_type": "text"
      },
      "source": [
        "## to check the data distribution in numerical values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9pDbZvMA82a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to check the data distribution in numerical values\n",
        "for i in df_numeric.columns:\n",
        "  print(i)\n",
        "  sns.distplot(df_numeric[i])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxDtqdqRD5aa",
        "colab_type": "text"
      },
      "source": [
        "## to check the data distribution in categorical values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSyghPazA2cY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# to check the data distribution in categorical values\n",
        "for i in df_category.columns:\n",
        "  df.groupby(i)['Income'].value_counts().unstack().plot(kind='bar',stacked=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEaGNspbbSU6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(25, 15))\n",
        "cols = 5\n",
        "rows = np.ceil(float(data_train.shape[1]) / cols)\n",
        "for i, column in enumerate(df_train.columns):\n",
        "    ax = fig.add_subplot(rows, cols, i + 1)\n",
        "    ax.set_title(column)\n",
        "    if df_train.dtypes[column] == np.object:\n",
        "        data_train[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
        "    else:\n",
        "        df_train[column].hist(axes=ax)\n",
        "        plt.xticks(rotation=\"vertical\")\n",
        "plt.subplots_adjust(hspace=0.7, wspace=0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAiqieCFG6_x",
        "colab_type": "text"
      },
      "source": [
        "## Remove outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfxa28ZWG_2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.boxplot(x=df['Price'])\n",
        "sns.boxplot(x=df['HP'])\n",
        "sns.boxplot(x=df['Cylinders'])\n",
        "\n",
        "# to define quartiles \n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 — Q1\n",
        "print(IQR)\n",
        "\n",
        "# to remove outleirs\n",
        "df = df[~((df < (Q1–1.5 * IQR)) |(df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om5Vi_6H9Dfe",
        "colab_type": "text"
      },
      "source": [
        "## for heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFZDb-X19CQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr = df1.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle; True = do NOT show\n",
        "mask = np.zeros_like(corr, dtype=np.bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(11, 9))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "# More details at https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
        "sns.heatmap(\n",
        "    corr,          # The data to plot\n",
        "    mask=mask,     # Mask some cells\n",
        "    cmap=cmap,     # What colors to plot the heatmap as\n",
        "    annot=True,    # Should the values be plotted in the cells?\n",
        "    vmax=.3,       # The maximum value of the legend. All higher vals will be same color\n",
        "    vmin=-.3,      # The minimum value of the legend. All lower vals will be same color\n",
        "    center=0,      # The center value of the legend. With divergent cmap, where white is\n",
        "    square=True,   # Force cells to be square\n",
        "    linewidths=.5, # Width of lines that divide cells\n",
        "    cbar_kws={\"shrink\": .5}  # Extra kwargs for the legend; in this case, shrink by 50%\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwtGMe75DzVk",
        "colab_type": "text"
      },
      "source": [
        "## Remove Correlated features above 0.75 and then apply logistic model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvqfPKgLCCH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove Correlated features above 0.75 and then apply logistic model\n",
        "corr_matrix = df1.drop(57,1).corr().abs()\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > 0.75)]\n",
        "print(\"Columns to be dropped: \")\n",
        "print(to_drop)\n",
        "df1.drop(to_drop,axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bdx6sqsIXGQ",
        "colab_type": "text"
      },
      "source": [
        "## to generate Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFuTXCF2IaGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding the relations between the variables.\n",
        "plt.figure(figsize=(20,10))\n",
        "c= df.corr()\n",
        "sns.heatmap(c,cmap=”BrBG”,annot=True)\n",
        "c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apuzfBtOEL7H",
        "colab_type": "text"
      },
      "source": [
        "## to convert categorical columns in to numerical values(dummies)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghSIcwodukMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in dataframe_cat.columns:\n",
        "  X_Dummy=pd.get_dummies(df_train[i],prefix=i)\n",
        "  df_train = pd.concat([df_train,X_Dummy], axis=1)\n",
        "  df_train.drop([i],axis=1,inplace=True)\n",
        "  ################################################'\n",
        "  for i in dataframe_cat.columns:\n",
        "  X_Dummy=pd.get_dummies(df_test[i],prefix=i)\n",
        "  df_test = pd.concat([df_test,X_Dummy], axis=1)\n",
        "  df_test.drop([i],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neC-W7QIETY7",
        "colab_type": "text"
      },
      "source": [
        "## Label encoder for categorical to numerical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdiBl2Eluool",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Label Encoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "dataframe_cat = df_train.select_dtypes(exclude=np.number)\n",
        "for x in dataframe_cat.columns:\n",
        "  le=LabelEncoder()\n",
        "  df_train[x] = le.fit_transform(df_train[x])\n",
        "  df_test[x] = le.transform(df_test[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_VA_4wLEnHs",
        "colab_type": "text"
      },
      "source": [
        "## Again concate numerical and categorical column in data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ-GP0LcbYfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = pd.concat([data_train[numerical_columns], pd.get_dummies(data_train[categorical_columns])], axis=1) \n",
        "data_test = pd.concat([data_test[numerical_columns],pd.get_dummies(data_test[categorical_columns])], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Fo5SU12Es5U",
        "colab_type": "text"
      },
      "source": [
        "## to split data in train and test for checking and scaling the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvq2L_uPVBL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X_train_new=X_train.drop(['ID'],axis=1)\n",
        "X_test_new=X_test.drop(['ID'],axis=1)\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train_new)\n",
        "X_train_new = scaler.transform(X_train_new)\n",
        "X_test_new = scaler.transform(X_test_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdYchqziFe1K",
        "colab_type": "text"
      },
      "source": [
        "## to run every model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzQEitrRvxVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def final_model(model,X_train, X_test, y_train):\n",
        "  model.fit(X_train_new,y_train)\n",
        "  pred=model.predict(X_test_new)\n",
        "  df_pred=pd.DataFrame(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YrOKbrAFhg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import precision_score, recall_score,confusion_matrix,accuracy_score,f1_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def accuracy_check(model,X,y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
        "  scores = cross_val_score(model, X_train, y_train, scoring='accuracy', n_jobs=-1, cv=10)\n",
        "  model.fit(X_train,y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"score is                           \", model.score(X_test,y_test))\n",
        "  print('Cross-validation mean accuracy is ',np.mean(scores) * 100)\n",
        "  print('Standard deviation of accuracy is ',np.std(scores) * 100,\".\")\n",
        "  print('Accuracy score of Model is        ',accuracy_score(y_test,y_pred))\n",
        "  print('Precision score of model is       ',precision_score(y_test,y_pred,average='weighted'))\n",
        "  print('Recall score of model is          ',recall_score(y_test,y_pred,average='weighted'))\n",
        "  print('F1 score of model is              ',f1_score(y_test,y_pred,average='weighted'))\n",
        "  print('ROC AUC score is                  ',roc_auc_score(y_test,y_pred,average='weighted'))\n",
        "  matrix=pd.DataFrame(confusion_matrix(y_test,y_pred),index=[['actual', 'actual'], ['spam', 'ham']],columns=[['predicted', 'predicted'], ['spam', 'ham']])\n",
        "  print(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmRTcPim9LJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import precision_score, recall_score,confusion_matrix,accuracy_score,f1_score,roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def accuracy_check(model,X,y):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)\n",
        "  scores = cross_val_score(model, X_train, y_train, scoring='accuracy', n_jobs=-1, cv=10)\n",
        "  model.fit(X_train,y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"score is                           \", model.score(X_test,y_test))\n",
        "  print('Cross-validation mean accuracy is ',np.mean(scores) * 100)\n",
        "  print('Standard deviation of accuracy is ',np.std(scores) * 100,\".\")\n",
        "  print('Accuracy score of Model is        ',accuracy_score(y_test,y_pred))\n",
        "  print('Precision score of model is       ',precision_score(y_test,y_pred))\n",
        "  print('Recall score of model is          ',recall_score(y_test,y_pred))\n",
        "  print('F1 score of model is              ',f1_score(y_test,y_pred))\n",
        "  print('ROC AUC score is                  ',roc_auc_score(y_test,y_pred))\n",
        "  matrix=pd.DataFrame(confusion_matrix(y_test,y_pred),index=[['actual', 'actual'], ['spam', 'ham']],columns=[['predicted', 'predicted'], ['spam', 'ham']])\n",
        "  print(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y50hCcKAMIKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca.n_components = 784\n",
        "pca_data = pca.fit_transform(X)\n",
        "percentage_var_explained = pca.explained_variance_ratio_\n",
        "cum_var_explained = np.cumsum(percentage_var_explained)\n",
        "fig = px.line(x =range(len(cum_var_explained)), y = cum_var_explained)\n",
        "fig.update_layout(xaxis_title= \"No_of_components\", \\\n",
        "                  yaxis_title= \"Cumulative Variance explained (%)\", \\\n",
        "                  font=dict(family= \"Courier New, monospace\", size=18 ,color=\"#7F7F7F\"))\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRcmCWZnsDTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sweetviz as sv \n",
        "#analyzing the dataset \n",
        "advert_report = sv.analyze(train) \n",
        "#display the report \n",
        "advert_report.show_html('Sweetviz.html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GJY00D_E9FQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Grid search for hyper parameter tuning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8-2ymtDFNpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCUAl4LsFTqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_params = {\n",
        "    'svm': {\n",
        "        'model': svm.SVC(gamma='auto'),\n",
        "        'params' : {\n",
        "            'C': [1,2,3,4,5,6],\n",
        "            'kernel': ['rbf','linear']\n",
        "        }  \n",
        "    },\n",
        "    'random_forest': {\n",
        "        'model': RandomForestClassifier(),\n",
        "        'params' : {\n",
        "            'n_estimators': [1000,1500,2000,2100,2200,2300,2400,2500],\n",
        "            'n_jobs':[-1]\n",
        "        }\n",
        "    },\n",
        "    'KNeighborsClassifier': {\n",
        "        'model':KNeighborsClassifier(),\n",
        "        'params':{\n",
        "            'n_neighbors':[2,3,4,5,6]\n",
        "        }\n",
        "    },\n",
        "    'Bagging':{\n",
        "        'model':BaggingClassifier(DecisionTreeClassifier()),\n",
        "        'params': {\n",
        "            'n_estimators':[500,1000,1500,2000,2100],\n",
        "            'max_samples':[100,200,300,400],\n",
        "            'bootstrap':[True,False],\n",
        "            'n_jobs':[-1]            \n",
        "        }\n",
        "    },\n",
        "    'Adaboost':{\n",
        "        'model': AdaBoostClassifier(DecisionTreeClassifier(max_depth=1)),\n",
        "        'params': {\n",
        "            'n_estimators':[500,1000,1500,2000,2100],\n",
        "            'algorithm':[\"SAMME.R\"],\n",
        "            'learning_rate':[0.1,0.2,0.3,0.01],\n",
        "            \n",
        "        }\n",
        "    }, \n",
        "    'SVC_poly': {\n",
        "        'model':SVC(),\n",
        "        'params': {\n",
        "            'kernel':[\"poly\"],\n",
        "            'degree':[2,3,4,5,6],\n",
        "             'coef0':[5,10,20,30],\n",
        "              'C':[1,2,3,4,5]            \n",
        "        }\n",
        "    }\n",
        "\n",
        "}\n",
        "\n",
        "scores = []\n",
        "\n",
        "for model_name, mp in model_params.items():\n",
        "    clf =  GridSearchCV(mp['model'], mp['params'], cv=5, return_train_score=False)\n",
        "    clf.fit(X_train_new, y)\n",
        "    scores.append({\n",
        "        'model': model_name,\n",
        "        'best_score': clf.best_score_,\n",
        "        'best_params': clf.best_params_\n",
        "    })\n",
        "    \n",
        "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIH5-HuXMsxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "7c216fb8-ece7-42e8-ae7b-f2dfd956e79c"
      },
      "source": [
        "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d8b041d73581>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'best_score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'best_params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txEI4zpAMtF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}